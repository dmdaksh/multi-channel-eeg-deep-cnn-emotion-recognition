{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DREAMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4aWHmYOC6m5q"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Activation, AvgPool1D, Dense, Conv1D, Flatten, Dropout, Input, BatchNormalization, GlobalMaxPool1D, MaxPool1D, SpatialDropout1D, GlobalAvgPool1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy import signal\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5zQTUcao6M0B"
   },
   "outputs": [],
   "source": [
    "sampling_rate = 128\n",
    "window_size = 1280\n",
    "overlap = 256\n",
    "channel_len = 14\n",
    "classes = 2\n",
    "\n",
    "bands = {'delta': [0.5/(sampling_rate/2), 4/(sampling_rate/2)], 'theta': [4/(sampling_rate/2), 8/(sampling_rate/2)], \\\n",
    "         'alpha': [8/(sampling_rate/2), 14/(sampling_rate/2)], 'beta': [14/(sampling_rate/2), 30/(sampling_rate/2)], \\\n",
    "         'gamma': [30/(sampling_rate/2), 50/(sampling_rate/2)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2kFj1lw2ZnlW"
   },
   "outputs": [],
   "source": [
    "def load_data(eeg_band = None):\n",
    "  \n",
    "  data = []\n",
    "  val_label = []\n",
    "  aro_label = []\n",
    "  dom_label = []\n",
    "  \n",
    "  for person in range(1,24):\n",
    "    \n",
    "    # Navigating through file directory\n",
    "    a = './Dreamer/person'\n",
    "    b = '/eeg_samples/eeg'\n",
    "    \n",
    "    print('Person No. ' + str(person))\n",
    "\n",
    "    # Loading Valence Label\n",
    "    valence = pd.read_csv(a+str(person)+'/eeg_labels/valence.csv', header = None)\n",
    "    valence = valence.values.ravel()\n",
    "    \n",
    "    # Loading Arousal Label\n",
    "    arousal = pd.read_csv(a+str(person)+'/eeg_labels/arousal.csv', header = None)\n",
    "    arousal = arousal.values.ravel()\n",
    "    \n",
    "    # Loading Dominance Label\n",
    "    dominance = pd.read_csv(a+str(person)+'/eeg_labels/dominance.csv', header = None)\n",
    "    dominance = dominance.values.ravel()\n",
    "    \n",
    "    # Assigning classes\n",
    "    valence[valence<=3]=0\n",
    "    valence[valence>3]=1  \n",
    "    arousal[arousal<=3]=0\n",
    "    arousal[arousal>3]=1\n",
    "    dominance[dominance<=3]=0\n",
    "    dominance[dominance>3]=1\n",
    "\n",
    "    # Preprocessing\n",
    "    for i in range(1,19):\n",
    "      eeg = pd.read_csv(a+str(person)+b+str(i)+'.csv', header=None)\n",
    "      eeg = eeg.values\n",
    "\n",
    "      num, den = signal.butter(4, bands[eeg_band], 'band') # Butterworth filter of order N = 4\n",
    "      band_signal = signal.filtfilt(num, den, eeg, axis=0)\n",
    "      eeg = band_signal\n",
    "      del band_signal, num, den\n",
    "      \n",
    "      scaler = StandardScaler().fit(eeg)\n",
    "      scaled_eeg = scaler.transform(eeg)\n",
    "      del eeg\n",
    "      \n",
    "      # Segmenting into 10 seconds (1280 timesteps) windows with 2 seconds (256 timesteps) overlap\n",
    "      start = 0\n",
    "      while start+window_size < scaled_eeg.shape[0]:\n",
    "        data.append(scaled_eeg[start:start+window_size,:])\n",
    "        val_label.append(valence[i-1])\n",
    "        aro_label.append(arousal[i-1])\n",
    "        dom_label.append(dominance[i-1])\n",
    "        start = start+overlap\n",
    "      del scaled_eeg\n",
    "\n",
    "  data = np.array(data, dtype = np.float32) # Using 32 bit floating point value to save memory\n",
    "  val_label = np.array(val_label, dtype = np.int8)\n",
    "  aro_label = np.array(aro_label, dtype = np.int8)\n",
    "  dom_label = np.array(dom_label, dtype = np.int8)\n",
    "\n",
    "  print(val_label.shape, val_label[val_label == 0].shape, val_label[val_label == 1].shape)\n",
    "  print(aro_label.shape, aro_label[aro_label == 0].shape, aro_label[aro_label == 1].shape)\n",
    "  print(dom_label.shape, dom_label[dom_label == 0].shape, dom_label[dom_label == 1].shape)\n",
    "\n",
    "  val_label = np_utils.to_categorical(val_label)\n",
    "  aro_label = np_utils.to_categorical(aro_label)\n",
    "  dom_label = np_utils.to_categorical(dom_label)      \n",
    "\n",
    "  \n",
    "  return (data, val_label, aro_label, dom_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dCc7FfhaD3VK",
    "outputId": "5435f5b4-8c08-4184-f0ce-8ca7bc811f71"
   },
   "outputs": [],
   "source": [
    "FOLD = 10 # Number of folds\n",
    "eeg_band = 'theta' # EEG band name\n",
    "\n",
    "data, valence, arousal, dominance = load_data(eeg_band) # Loading processed data\n",
    "\n",
    "nb_samples = data.shape[0] # Number of samples\n",
    "factor = nb_samples//FOLD # Kth fold by this factor\n",
    "\n",
    "shuffler = np.random.permutation(nb_samples) # Shuffling data\n",
    "\n",
    "data = data[shuffler]\n",
    "valence = valence[shuffler]\n",
    "arousal = arousal[shuffler]\n",
    "dominance = dominance[shuffler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-96-y4XOZHxe"
   },
   "outputs": [],
   "source": [
    "eeg_input = Input(shape = (window_size, channel_len), name='eeg_input') # Input layer\n",
    "\n",
    "# CNN model\n",
    "def get_CNN():\n",
    "  x = Conv1D(filters = 32, kernel_size = 5, strides = 2, padding = 'valid', activation='relu', name='conv1')(eeg_input)\n",
    "  x = Conv1D(filters = 32, kernel_size = 5, strides = 2, padding = 'valid', activation='relu', name='conv2')(x)\n",
    "  x = AvgPool1D(pool_size=2, name='avg_pool1')(x)\n",
    "  x = BatchNormalization(name='batch_norm1')(x)\n",
    "  x = SpatialDropout1D(rate=0.125, name = 'spatial_dropout1')(x)\n",
    "  x = Conv1D(filters = 64, kernel_size = 5, strides = 2, padding = 'valid', activation='relu', name='conv3')(x)\n",
    "  x = Conv1D(filters = 64, kernel_size = 5, strides = 2, padding = 'valid', activation='relu', name='conv4')(x)\n",
    "  x = AvgPool1D(pool_size=2, name='avg_pool2')(x)\n",
    "  x = BatchNormalization(name='batch_norm2')(x)\n",
    "  x = SpatialDropout1D(rate=0.25, name = 'spatial_dropout2')(x)\n",
    "  x = Conv1D(filters = 128, kernel_size = 3, strides = 1, padding = 'valid', activation='relu', name='conv5')(x)\n",
    "  x = Conv1D(filters = 128, kernel_size = 3, strides = 1, padding = 'valid', activation='relu', name='conv6')(x)\n",
    "  x = AvgPool1D(pool_size=2, name='avg_pool3')(x)\n",
    "  x = BatchNormalization(name='batch_norm3')(x)\n",
    "  x = SpatialDropout1D(rate=0.5, name = 'spatial_dropout3')(x)\n",
    "  x = Conv1D(filters = 512, kernel_size = 3, strides = 1, padding = 'valid', activation='relu', name='conv7')(x)\n",
    "  x = Conv1D(filters = 512, kernel_size = 3, strides = 1, padding = 'valid', activation='relu', name='conv8')(x)\n",
    "  x = GlobalAvgPool1D(name='global_pool1')(x)\n",
    "  x = BatchNormalization(name='batch_norm4')(x)\n",
    "  x = Dropout(0.5)(x)\n",
    "  x = Dense(64)(x)\n",
    "  x = Activation('tanh')(x)\n",
    "  x = Dense(8)(x)\n",
    "  x = Activation('tanh')(x)\n",
    "  x = Dropout(0.25, )(x)\n",
    "  return x\n",
    "\n",
    "def get_model():\n",
    "  x = get_CNN()\n",
    "\n",
    "  out = Dense(classes, activation='softmax', name = 'output')(x) # Output layer\n",
    "\n",
    "  model = Model(inputs=eeg_input, outputs=out) # Creating a model instance\n",
    "  \n",
    "  adam = Adam(lr=1e-3,decay=1e-5) # Adam optimizer\n",
    "  \n",
    "  model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['categorical_accuracy']) # Compiling model\n",
    "  model.summary()\n",
    "  \n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TKFcY_TjhVM0"
   },
   "outputs": [],
   "source": [
    "val_res = {'accuracy': [], 'confusion_matrix': []}\n",
    "\n",
    "for i in range(FOLD):\n",
    "  X_train = np.concatenate((data[0 : i*factor], data[(i+1)*factor : nb_samples])) # Training data\n",
    "  X_test = data[i*factor : (i+1)*factor] # Testing data\n",
    "  val_train = np.concatenate((valence[0 : i*factor], valence[(i+1)*factor : nb_samples])) # Valence training labels\n",
    "  val_test = valence[i*factor : (i+1)*factor] # Valence testing labels\n",
    "\n",
    "  model = get_model()\n",
    "  model.fit(X_train, val_train, epochs = 100, batch_size = 1024, shuffle = True) \n",
    "  \n",
    "  acc = model.evaluate(X_test, val_test)\n",
    "  print(acc)\n",
    "\n",
    "  val_res['accuracy'].append(acc)\n",
    "\n",
    "  pred = model.predict(X_test)\n",
    "  val_res['confusion_matrix'].append(confusion_matrix(val_test.argmax(1), pred.argmax(1)))\n",
    "\n",
    "    \n",
    "# Dumping valence results\n",
    "file = './eeg_data/Dreamer_valence_' + eeg_band + '.pkl'\n",
    "\n",
    "with open(file, 'wb') as f:\n",
    "  pkl.dump(val_res, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jpLBI0SvEyEU",
    "outputId": "45458afa-1683-4f60-af96-6b366724b3ef"
   },
   "outputs": [],
   "source": [
    "for i in val_res['accuracy']:\n",
    "  print(round(i[1]*100, 2)) # Rounding off to two decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x4QmKreVE6d0",
    "outputId": "5d2a9fd9-d169-4093-f337-79509808f9e3"
   },
   "outputs": [],
   "source": [
    "for i in val_res['confusion_matrix']:\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "H2Nf25g6Dxlq",
    "outputId": "3912b6e7-3b03-4775-94bc-b5e4f2bc36ba"
   },
   "outputs": [],
   "source": [
    "aro_res = {'accuracy': [], 'confusion_matrix': []}\n",
    "\n",
    "for i in range(FOLD):\n",
    "  X_train = np.concatenate((data[0 : i*factor], data[(i+1)*factor : nb_samples])) # Training data\n",
    "  X_test = data[i*factor : (i+1)*factor] # Testing data\n",
    "  aro_train = np.concatenate((arousal[0 : i*factor], arousal[(i+1)*factor : nb_samples])) # Arousal training labels\n",
    "  aro_test = arousal[i*factor : (i+1)*factor] # Arousal testing labels\n",
    "\n",
    "  model = get_model()\n",
    "  model.fit(X_train, aro_train, epochs = 100, batch_size = 1024, shuffle = True)\n",
    "\n",
    "  acc = model.evaluate(X_test, aro_test)\n",
    "  print(acc)\n",
    "    \n",
    "  aro_res['accuracy'].append(acc)\n",
    "\n",
    "  pred = model.predict(X_test)\n",
    "  aro_res['confusion_matrix'].append(confusion_matrix(aro_test.argmax(1), pred.argmax(1)))\n",
    "\n",
    "\n",
    "# Dumping arousal results\n",
    "file = './eeg_data/Dreamer_arousal_' + eeg_band + '.pkl'\n",
    "\n",
    "with open(file, 'wb') as f:\n",
    "  pkl.dump(aro_res, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N6AjGxKbU3Tx",
    "outputId": "91eb8b34-cae7-4058-ab9e-288b590039df"
   },
   "outputs": [],
   "source": [
    "for i in aro_res['accuracy']:\n",
    "  print(round(i[1]*100, 2)) # Rounding off to two decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OEf_sIyvU53i",
    "outputId": "17b7646c-6e65-4d8d-96c5-984f4a1da64b"
   },
   "outputs": [],
   "source": [
    "for i in aro_res['confusion_matrix']:\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dominance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qBt8j_mSDxqc"
   },
   "outputs": [],
   "source": [
    "dom_res = {'accuracy': [], 'confusion_matrix': []}\n",
    "\n",
    "for i in range(FOLD):\n",
    "  X_train = np.concatenate((data[0 : i*factor], data[(i+1)*factor : nb_samples])) # Training data\n",
    "  X_test = data[i*factor : (i+1)*factor] # Testing data\n",
    "  dom_train = np.concatenate((dominance[0 : i*factor], dominance[(i+1)*factor : nb_samples])) # Dominance training labels\n",
    "  dom_test = dominance[i*factor : (i+1)*factor] # Dominance testing labels\n",
    "\n",
    "  model = get_model()\n",
    "  model.fit(X_train, dom_train, epochs = 100, batch_size = 1024, shuffle = True)\n",
    "\n",
    "  acc = model.evaluate(X_test, dom_test)\n",
    "  print(acc)\n",
    "    \n",
    "  dom_res['accuracy'].append(acc)\n",
    "\n",
    "  pred = model.predict(X_test)\n",
    "  dom_res['confusion_matrix'].append(confusion_matrix(dom_test.argmax(1), pred.argmax(1)))\n",
    "\n",
    "\n",
    "# Dumping dominance results\n",
    "file = './eeg_data/Dreamer_dominance_' + eeg_band + '.pkl'\n",
    "\n",
    "with open(file, 'wb') as f:\n",
    "  pkl.dump(dom_res, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eb0aXUPJWCcy",
    "outputId": "cd4a5f28-040c-41e7-8957-71607adf8e12"
   },
   "outputs": [],
   "source": [
    "for i in dom_res['accuracy']:\n",
    "  print(round(i[1]*100, 2)) # Rounding off to two decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ce7eUxSMVsou",
    "outputId": "21d87663-f821-494a-d644-f676b257b500"
   },
   "outputs": [],
   "source": [
    "for i in dom_res['confusion_matrix']:\n",
    "  print(i)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "DREAMER.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
